{"cells":[{"cell_type":"markdown","id":"945d2086","metadata":{"id":"945d2086"},"source":["# 0 Set paths, devices, etc."]},{"cell_type":"code","execution_count":null,"id":"16UUZ4LuPDU5","metadata":{"executionInfo":{"elapsed":12209,"status":"error","timestamp":1716828996581,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-120},"id":"16UUZ4LuPDU5","colab":{"base_uri":"https://localhost:8080/","height":386},"outputId":"cba54274-059b-4306-becc-58d5f0ca3f20"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'evaluate'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-8e3b41db2911>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;31m#, accuracy_score, precision_score, recall_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import sys\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","from datasets import Dataset, DatasetDict\n","import torch.nn as nn\n","\n","from transformers import PreTrainedTokenizerFast, TrainingArguments, Trainer, default_data_collator, MambaConfig\n","\n","from sklearn.metrics import f1_score, confusion_matrix #, accuracy_score, precision_score, recall_score\n","import evaluate\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import bitsandbytes as bnb\n","\n","import accelerate\n","\n","from hf_mamba_classification import MambaForSequenceClassification"]},{"cell_type":"code","execution_count":null,"id":"4978325a","metadata":{"id":"4978325a"},"outputs":[],"source":["# notebook_login()"]},{"cell_type":"code","execution_count":null,"id":"mNy3kQcq3gHA","metadata":{"id":"mNy3kQcq3gHA"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"dkmIqKEI4j1j","metadata":{"id":"dkmIqKEI4j1j"},"outputs":[],"source":["data_dir = 'drive/MyDrive/neuro2voc/task_1/data/'\n","# data_dir = '/home/zubat/Fei/Task_1/outputs/'"]},{"cell_type":"code","execution_count":null,"id":"618f73da","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716828952803,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-120},"id":"618f73da","outputId":"cf369627-49b5-4f8d-e596-a324500aac84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()"]},{"cell_type":"markdown","id":"b78465e6","metadata":{"id":"b78465e6"},"source":["# 1 Load data and inspect"]},{"cell_type":"markdown","id":"59b5acfb","metadata":{"id":"59b5acfb"},"source":["### 1.0 select what you want to load"]},{"cell_type":"code","execution_count":null,"id":"13d1ef51","metadata":{"id":"13d1ef51"},"outputs":[],"source":["from datasets import load_dataset\n","\n","imdb = load_dataset(\"imdb\")"]},{"cell_type":"markdown","id":"50204407","metadata":{"id":"50204407"},"source":["### 1.1 Load the data"]},{"cell_type":"code","execution_count":null,"id":"d3d28144","metadata":{"executionInfo":{"elapsed":18038,"status":"ok","timestamp":1710682636729,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"d3d28144","outputId":"a3e19b49-1584-4187-8dfe-aaa05df53310"},"outputs":[{"data":{"text/plain":["{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clich√©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n"," 'label': 0}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["imdb[\"test\"][0]"]},{"cell_type":"markdown","id":"0d3df729","metadata":{"id":"0d3df729"},"source":["# 2 Prepare for the model"]},{"cell_type":"markdown","id":"c55f880c","metadata":{"id":"c55f880c"},"source":["### 2.1 Tokenize function"]},{"cell_type":"code","execution_count":null,"id":"0afe82ab","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710682686508,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"0afe82ab","outputId":"aaf5c787-56a7-4549-9e9f-08ab1104b864"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zubat/miniforge3/envs/neuro2voc/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"id":"1771140e","metadata":{"id":"1771140e"},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True)"]},{"cell_type":"code","execution_count":null,"id":"a1263779","metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["db4e8c8745de48e2bfcc573815855614"]},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1710683010486,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"a1263779","outputId":"6e0c2a2e-1ade-49ee-daa9-852b37f3fcff"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db4e8c8745de48e2bfcc573815855614","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_imdb = imdb.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":null,"id":"04e3fa23","metadata":{"id":"04e3fa23"},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"721c1bb2","metadata":{"id":"721c1bb2"},"outputs":[],"source":["accuracy = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":null,"id":"e1de04f6","metadata":{"id":"e1de04f6"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"id":"b5929c3f","metadata":{"id":"b5929c3f"},"outputs":[],"source":["id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"]},{"cell_type":"markdown","id":"3467fa8d","metadata":{"id":"3467fa8d"},"source":["### 2.2 Train Test Split"]},{"cell_type":"code","execution_count":null,"id":"7a5d893b","metadata":{"executionInfo":{"elapsed":3765,"status":"ok","timestamp":1710683014237,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"7a5d893b","outputId":"9cf78299-e2d9-439a-935a-867ca0dee3cc"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 25000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 25000\n","    })\n","    unsupervised: Dataset({\n","        features: ['text', 'label', 'input_ids', 'attention_mask'],\n","        num_rows: 50000\n","    })\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_imdb"]},{"cell_type":"markdown","id":"439d3025","metadata":{"id":"439d3025"},"source":["### 2.3 Data collator"]},{"cell_type":"markdown","id":"722f4d24","metadata":{"id":"722f4d24"},"source":["### 2.4 Model Config"]},{"cell_type":"markdown","id":"43fbf8bc","metadata":{"id":"43fbf8bc"},"source":["#### 2.4.3 Input size"]},{"cell_type":"code","execution_count":null,"id":"a040f59d","metadata":{"id":"a040f59d","outputId":"5a215161-80c4-4b00-ded3-1f9fb308d551"},"outputs":[{"data":{"text/plain":["133"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(tokenized_imdb['train']['input_ids'][2])"]},{"cell_type":"markdown","id":"437fe049","metadata":{"id":"437fe049"},"source":["#### 2.4.5 Model Path"]},{"cell_type":"code","execution_count":null,"id":"68c703d8","metadata":{"id":"68c703d8"},"outputs":[],"source":["model_path = 'state-spaces/mamba-130m-hf'\n","tokenizer = AutoTokenizer.from_pretrained(model_path, add_eos_token=True)"]},{"cell_type":"markdown","id":"1254a468","metadata":{"id":"1254a468","notebookRunGroups":{"groupValue":"2"}},"source":["### 2.5 Load the model"]},{"cell_type":"markdown","id":"d7108fc8","metadata":{"notebookRunGroups":{"groupValue":"2"},"id":"d7108fc8"},"source":["#### Local Model"]},{"cell_type":"code","execution_count":null,"id":"6a2b4e3d","metadata":{"id":"6a2b4e3d"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",")"]},{"cell_type":"code","execution_count":null,"id":"bb23788c","metadata":{"id":"bb23788c","outputId":"41819ead-49cf-41e6-c828-9fbb1f4d10a4"},"outputs":[{"data":{"text/plain":["MambaConfig {\n","  \"bos_token_id\": 0,\n","  \"conv_kernel\": 4,\n","  \"eos_token_id\": 0,\n","  \"expand\": 2,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"NEGATIVE\",\n","    \"1\": \"POSITIVE\"\n","  },\n","  \"initializer_range\": 0.1,\n","  \"intermediate_size\": 1536,\n","  \"label2id\": {\n","    \"NEGATIVE\": 0,\n","    \"POSITIVE\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"mamba\",\n","  \"num_hidden_layers\": 32,\n","  \"pad_token_id\": 0,\n","  \"rescale_prenorm_residual\": false,\n","  \"residual_in_fp32\": true,\n","  \"state_size\": 16,\n","  \"time_step_floor\": 0.0001,\n","  \"time_step_init_scheme\": \"random\",\n","  \"time_step_max\": 0.1,\n","  \"time_step_min\": 0.001,\n","  \"time_step_rank\": 48,\n","  \"time_step_scale\": 1.0,\n","  \"transformers_version\": \"4.40.2\",\n","  \"use_bias\": false,\n","  \"use_cache\": false,\n","  \"use_conv_bias\": true,\n","  \"vocab_size\": 30522\n","}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["configuration = MambaConfig(\n","    num_labels=2,\n","    use_cache=False,\n","    id2label=id2label,\n","    label2id=label2id\n","    # hidden_size=768,\n","    # hidden_dropout_prob=0.1,\n","    # num_attention_heads=num_attention_heads,\n","    # num_hidden_layers=num_hidden_layers\n",")\n","model = MambaForSequenceClassification(configuration)\n","model.resize_token_embeddings(len(tokenizer))\n","model.config"]},{"cell_type":"markdown","id":"866b05ab","metadata":{"id":"866b05ab"},"source":["### 2.6 Training arguments"]},{"cell_type":"markdown","id":"ec84273d","metadata":{"id":"ec84273d"},"source":["#### 2.6.3 Training Arguments"]},{"cell_type":"code","execution_count":null,"id":"47e603e2","metadata":{"id":"47e603e2"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=64,\n","    per_device_eval_batch_size=64,\n","    num_train_epochs=5,\n","    # gradient_accumulation_steps = 2,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_imdb[\"train\"],\n","    eval_dataset=tokenized_imdb[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"id":"b2c01cef","metadata":{"colab":{"referenced_widgets":["a93022f5ae8e416b9748d69cfe1d1f0e","3773f10983fa4750ab107cef56fe198f","6f31118c7f6e478289db9235d123ec9a"]},"id":"b2c01cef","outputId":"22e57501-5e96-40d2-83a5-927cf9a4600a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a93022f5ae8e416b9748d69cfe1d1f0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1955 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3773f10983fa4750ab107cef56fe198f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.7159844040870667, 'eval_accuracy': 0.51424, 'eval_runtime': 277.8562, 'eval_samples_per_second': 89.975, 'eval_steps_per_second': 1.407, 'epoch': 1.0}\n","{'loss': 0.7175, 'grad_norm': 2.125091314315796, 'learning_rate': 1.4884910485933506e-05, 'epoch': 1.28}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f31118c7f6e478289db9235d123ec9a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.7128229141235352, 'eval_accuracy': 0.51656, 'eval_runtime': 279.3932, 'eval_samples_per_second': 89.48, 'eval_steps_per_second': 1.399, 'epoch': 2.0}\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/neuro2voc/lib/python3.12/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/neuro2voc/lib/python3.12/site-packages/transformers/trainer.py:2208\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"9a097d47","metadata":{"id":"9a097d47"},"outputs":[],"source":["# optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n","# optimizer = AdamW(model.parameters(), lr=1e-5)"]},{"cell_type":"markdown","id":"e2dd0499","metadata":{"id":"e2dd0499"},"source":["# 4 Test"]},{"cell_type":"code","execution_count":null,"id":"b61c5ffe","metadata":{"id":"b61c5ffe","outputId":"221db886-1127-415a-81c0-0729e60227c7"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                  \n"," 25%|‚ñà‚ñà‚ñå       | 304/1210 [19:18<50:22,  3.34s/it]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.581371784210205, 'eval_accuracy': 0.2906048906048906, 'eval_runtime': 100.1513, 'eval_samples_per_second': 77.583, 'eval_steps_per_second': 4.853, 'epoch': 2.5}\n","{'eval_loss': 1.581371784210205, 'eval_accuracy': 0.2906048906048906, 'eval_runtime': 100.1513, 'eval_samples_per_second': 77.583, 'eval_steps_per_second': 4.853, 'epoch': 2.5}\n"]}],"source":["test_result = trainer.evaluate(tokenized_imdb['train'])\n","print(test_result)"]},{"cell_type":"code","execution_count":null,"id":"b6a6f54c","metadata":{"id":"b6a6f54c","outputId":"a36c9940-7612-4fa7-bbb8-5492b1587ee5"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                  \n"," 25%|‚ñà‚ñà‚ñå       | 304/1210 [19:39<50:22,  3.34s/it]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5775818824768066, 'eval_accuracy': 0.26666666666666666, 'eval_runtime': 21.5351, 'eval_samples_per_second': 77.315, 'eval_steps_per_second': 4.876, 'epoch': 2.5}\n","{'eval_loss': 1.5775818824768066, 'eval_accuracy': 0.26666666666666666, 'eval_runtime': 21.5351, 'eval_samples_per_second': 77.315, 'eval_steps_per_second': 4.876, 'epoch': 2.5}\n"]}],"source":["test_result = trainer.evaluate(tokenized_imdb['test'])\n","print(test_result)"]},{"cell_type":"code","execution_count":null,"id":"e41c06a5","metadata":{"id":"e41c06a5","outputId":"ea410c77-f265-4bf9-938a-1f04118f1326"},"outputs":[{"name":"stderr","output_type":"stream","text":[]}],"source":["predictions = trainer.predict(tokenized_imdb['test'])\n","logits = predictions.predictions\n","predicted_classes = np.argmax(logits, axis=1)\n","true_labels = tokenized_imdb['test']['labels']"]},{"cell_type":"markdown","id":"033b3ff8","metadata":{"id":"033b3ff8"},"source":["# 5 Result"]},{"cell_type":"code","execution_count":null,"id":"a1f6ba3e","metadata":{"id":"a1f6ba3e","outputId":"cc9d3493-f78b-49d1-e86d-d3743a8c3908"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x800 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["cm = confusion_matrix(true_labels, predicted_classes)\n","\n","# Plotting the confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"markdown","id":"ae6e79a2","metadata":{"id":"ae6e79a2"},"source":["temporal 120: doesnt work, predict only label 1 and 5\n","\n","spatial data: doesnt work, predict only label"]},{"cell_type":"code","execution_count":null,"id":"5eb6122b","metadata":{"id":"5eb6122b"},"outputs":[],"source":["name_model = \"spatial_600ms_150epochs\"\n","trainer.save_model(f\"{data_dir}5_models/{name_model}\")"]},{"cell_type":"markdown","id":"755a8b66","metadata":{"id":"755a8b66"},"source":["# Archived Codes"]},{"cell_type":"code","execution_count":null,"id":"95b80802","metadata":{"id":"95b80802"},"outputs":[],"source":["from datasets import load_dataset\n","from trl import SFTTrainer\n","from peft import LoraConfig\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n","model_id = \"state-spaces/mamba-130m-hf\"\n","model = AutoModelForCausalLM.from_pretrained(model_id)\n","dataset = load_dataset(\"Abirate/english_quotes\", split=\"train\")\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    learning_rate=2e-3\n",")\n","lora_config =  LoraConfig(\n","        r=8,\n","        target_modules=[\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"],\n","        task_type=\"CAUSAL_LM\",\n","        bias=\"none\"\n",")\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    peft_config=lora_config,\n","    train_dataset=dataset,\n","    dataset_text_field=\"quote\",\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"7d7b87dd","metadata":{"id":"7d7b87dd"},"outputs":[],"source":["input_ids = torch.tensor([[101, 102, ...]])  # Example input tensor\n","outputs = model(input_ids)\n","print(outputs.logits.shape)  # This should output (1, 6) for your configuration\n"]},{"cell_type":"code","execution_count":null,"id":"adb49b85","metadata":{"id":"adb49b85"},"outputs":[],"source":["test_input = torch.tensor(dataset_dict['train']['input_ids'][1], device=device)"]},{"cell_type":"code","execution_count":null,"id":"7009ff2c","metadata":{"id":"7009ff2c"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"96006d68","metadata":{"id":"96006d68","outputId":"5c33433c-9585-4e64-802f-f3501b02e6ae"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":null,"id":"9db0d6ad","metadata":{"id":"9db0d6ad","outputId":"4dcbda38-f145-471f-a530-571ceafa64df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Adjusted Input Shape: torch.Size([1, 1800])\n","Output Keys: dict_keys(['logits'])\n","Logits Shape: torch.Size([6])\n"]}],"source":["\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Prepare the test input and add a batch dimension if necessary\n","test_input = torch.tensor(dataset_dict['train']['input_ids'][1], device=device)\n","if test_input.ndim == 1:\n","    test_input = test_input.unsqueeze(0)  # Reshape to [1, sequence_length]\n","\n","# Print the adjusted input shape\n","print(\"Adjusted Input Shape:\", test_input.shape)\n","\n","# Try to get the output from the model\n","try:\n","    output = model(test_input)\n","    # Check what keys are in the output dictionary\n","    print(\"Output Keys:\", output.keys())\n","    # Access logits if available\n","    if 'logits' in output:\n","        print(\"Logits Shape:\", output['logits'].shape)\n","    else:\n","        print(\"Logits key not found in model output.\")\n","except Exception as e:\n","    print(\"Error during model evaluation:\", e)\n"]},{"cell_type":"code","execution_count":null,"id":"252e322b","metadata":{"id":"252e322b","outputId":"abda25c0-f18f-4cfb-d0be-db849396e7d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output logits: tensor([-0.5986,  1.3730,  0.0273,  0.9082, -0.9707,  1.2109], device='cuda:0')\n","Predictions: 1\n","Label: 5\n"]}],"source":["example_inputs = torch.tensor(tokenized_dataset[500]['input_ids'], device=device)\n","example_labels = torch.tensor(tokenized_dataset[500]['labels'], device=device)\n","\n","model.eval()\n","with torch.no_grad():\n","    outputs = model(example_inputs.unsqueeze(0))  # Add batch dimension\n","    logits = outputs['logits']\n","    print(f\"Output logits: {logits}\")\n","\n","# Check outputs\n","predictions = torch.argmax(logits, dim=-1)\n","print(f\"Predictions: {predictions}\")\n","print(f\"Label: {example_labels}\")\n"]},{"cell_type":"code","execution_count":null,"id":"a3f940ed","metadata":{"id":"a3f940ed","outputId":"52f13fe3-6446-4aec-b1d8-2b2dd054c162"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input IDs: [0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 97, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 55, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 68, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 156, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 1467, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 98, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 134, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 39, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 125, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 151, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 142, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 4708, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 124, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 2010, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 125, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 180, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 145, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 93, 1, 0, 39, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 114, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 180, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 189, 1, 0, 12, 1, 0, 113, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 149, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 149, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 156, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 114, 1, 0, 12, 1, 0, 209, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 126, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 144, 1, 0, 12, 1, 0, 134, 1, 0, 12, 1, 0, 12, 1, 0, 149, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 446, 1, 0, 12, 1, 0, 95, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 103, 1, 0, 12, 1, 0, 48, 1, 0, 12, 1, 0, 149, 1, 0, 144, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 95, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1]\n","Label: 5\n","Input IDs: [0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 93, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 85, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 159, 1, 0, 12, 1, 0, 68, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 113, 1, 0, 12, 1, 0, 12, 1, 0, 234, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 112, 1, 0, 39, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 106, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 34, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 126, 1, 0, 12, 1, 0, 12, 1, 0, 178, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 58, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 106, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 85, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 34, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 100, 1, 0, 12, 1, 0, 12, 1, 0, 148, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 101, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 93, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 205, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 100, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 142, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 2938, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 87, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 151, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 3704, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1]\n","Label: 3\n","Input IDs: [0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 113, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 5816, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 58, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 85, 1, 0, 113, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 85, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 85, 1, 0, 12, 1, 0, 12, 1, 0, 113, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 58, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 100, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 68, 1, 0, 12, 1, 0, 154, 1, 0, 12, 1, 0, 145, 1, 0, 101, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 48, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 97, 1, 0, 136, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 68, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 75, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 99, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 92, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 220, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 68, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 75, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 136, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 68, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 225, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 99, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 34, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 194, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 59, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 87, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 159, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 178, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 301, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 98, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 48, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 1228, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1]\n","Label: 3\n","Input IDs: [0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 178, 1, 0, 12, 1, 0, 12, 1, 0, 36, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 41, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 136, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 72, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 136, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 201, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 36, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 153, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 136, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 41, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 97, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 12, 1, 0, 12, 1, 0, 103, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 97, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 39, 1, 0, 108, 1, 0, 100, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 97, 1, 0, 12, 1, 0, 12, 1, 0, 2333, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 153, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 108, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 41, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 55, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1]\n","Label: 3\n","Input IDs: [0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 48, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 189, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 87, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 85, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 72, 1, 0, 12, 1, 0, 113, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 264, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 34, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 58, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 124, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 177, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 58, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 56, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 189, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 101, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 220, 1, 0, 145, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 148, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 12, 1, 0, 106, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 177, 1, 0, 22, 1, 0, 114, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 148, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 111, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 215, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 148, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 177, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 134, 1, 0, 159, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 35, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 84, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 106, 1, 0, 12, 1, 0, 12, 1, 0, 22, 1, 0, 12, 1, 0, 180, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 101, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 112, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 20, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 114, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 59, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 41, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1, 0, 12, 1]\n","Label: 1\n"]}],"source":["for i in range(5):\n","    print(f\"Input IDs: {dataset_dict['train'][i]['input_ids']}\")\n","    print(f\"Label: {dataset_dict['train'][i]['labels']}\")"]},{"cell_type":"code","execution_count":null,"id":"1322e0c3","metadata":{"id":"1322e0c3","outputId":"b4deeb93-41f4-46de-bf89-cc845b048e21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input IDs Shape: torch.Size([1800])\n","Labels: 0\n","Input IDs Shape: torch.Size([1800])\n","Labels: 0\n","Input IDs Shape: torch.Size([1800])\n","Labels: 0\n","Input IDs Shape: torch.Size([1800])\n","Labels: 0\n","Input IDs Shape: torch.Size([1800])\n","Labels: 1\n","Input IDs Shape: torch.Size([1800])\n","Labels: 1\n"]}],"source":["for i, data in enumerate(tokenized_dataset):\n","    print(f\"Input IDs Shape: {torch.tensor(data['input_ids']).shape}\")  # Expected: [1, 1800] if batch size is 1\n","    print(f\"Labels: {torch.tensor(data['labels'])}\")  # Should show only one label per batch\n","    if i == 5:  # Check only the first batch to avoid flooding the output\n","        break\n"]},{"cell_type":"code","execution_count":null,"id":"dfe17d65","metadata":{"id":"dfe17d65","outputId":"b3a53e61-b71e-4e98-ea36-e94beb2cedac"},"outputs":[{"data":{"text/plain":["[0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 151,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 22,\n"," 1,\n"," 0,\n"," 20,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 56,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 75,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 34,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 4436,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 22,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 68,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 75,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 35,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 95,\n"," 1,\n"," 0,\n"," 20,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 99,\n"," 1,\n"," 0,\n"," 68,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 125,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 95,\n"," 1,\n"," 0,\n"," 75,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 22,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 20,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 194,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 22,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 20,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 22,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 189,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 34,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 20,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 170,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," 12,\n"," 1,\n"," 0,\n"," ...]"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["example_inputs"]},{"cell_type":"code","execution_count":null,"id":"5da4660b","metadata":{"id":"5da4660b","outputId":"5aff583e-ac4d-4b00-fa4d-8e3389ee72dc"},"outputs":[{"ename":"KeyError","evalue":"'input_ids'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient computation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m subset_loader:\n\u001b[0;32m---> 10\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Ensure data is on the correct device\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n","\u001b[0;31mKeyError\u001b[0m: 'input_ids'"]}],"source":["import torch\n","from torch.utils.data import DataLoader\n","\n","# Assuming you have a dataset and a DataLoader set up\n","subset_loader = DataLoader(dataset, batch_size=10, shuffle=True)  # Small batch size for testing\n","\n","model.eval()  # Set model to evaluation mode to disable dropout, batch norm, etc.\n","with torch.no_grad():  # Disable gradient computation\n","    for batch in subset_loader:\n","        inputs, labels = batch['input_ids'], batch['labels']\n","        inputs, labels = inputs.to(device), labels.to(device)  # Ensure data is on the correct device\n","\n","        outputs = model(inputs)\n","        logits = outputs['logits']\n","        predictions = torch.argmax(logits, dim=-1)\n","\n","        # Check shapes and content\n","        print(\"Logits Shape:\", logits.shape)\n","        print(\"Predictions Shape:\", predictions.shape)\n","        print(\"Labels Shape:\", labels.shape)\n","        print(\"First 5 Predictions:\", predictions[:5])\n","        print(\"First 5 Labels:\", labels[:5])\n","\n","        # Break after first batch to just see one batch of outputs\n","        break\n"]},{"cell_type":"code","execution_count":null,"id":"DYwN8ffrQ3d3","metadata":{"id":"DYwN8ffrQ3d3"},"outputs":[],"source":["class SPKDataset(Dataset):\n","    def __init__(self, dataset, label, split='train'):\n","        self.dataset = dataset\n","        self.split = split\n","        self.label = label\n","        self.label2id = {label: label - 2 for label in range(2, 9)}\n","\n","    def __getitem__(self, item):\n","        data = self.dataset[item]\n","        label = self.label[item]\n","        mapped_label = self.label2id.get(label, label)\n","        return data, mapped_label\n","\n","    def __len__(self):\n","        return len(self.dataset)"]},{"cell_type":"code","execution_count":null,"id":"eeef2556","metadata":{"id":"eeef2556"},"outputs":[],"source":["class SPKNoPadCollator:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, batch):\n","        data, labels = zip(*batch)\n","\n","        # tokenizer without padding and truncation\n","        inputs = self.tokenizer(list(data), return_tensors='pt')\n","\n","        # extract input_ids and attention_mask\n","        input_ids = inputs['input_ids']\n","        attention_mask = inputs['attention_mask']\n","        labels_tensor = torch.tensor(labels, dtype=torch.long)\n","\n","        return input_ids, attention_mask, labels_tensor"]},{"cell_type":"code","execution_count":null,"id":"7CBPI_u0USN3","metadata":{"id":"7CBPI_u0USN3"},"outputs":[],"source":["class SPKPadCollator:\n","    def __init__(self, tokenizer, max_len=512):\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __call__(self, batch):\n","        data, labels = zip(*batch)\n","\n","        # tokenize WITH padding\n","        input_ids = []\n","        attention_mask = []\n","        for datapoint in data:\n","            encoded = self.tokenizer.encode(datapoint)\n","            ids = encoded.ids\n","\n","            # truncate\n","            ids = ids[:self.max_len]\n","\n","            # create attention mask and pad input_ids\n","            mask = [1] * len(ids)\n","            num_pad = self.max_len - len(ids)\n","            ids += [self.tokenizer.token_to_id(\"[PAD]\")] * num_pad\n","            mask += [0] * num_pad\n","\n","            input_ids.append(ids)\n","            attention_mask.append(mask)\n","\n","        # convert to tensors\n","        input_ids_tensor = torch.tensor(input_ids, dtype=torch.long)\n","        attention_mask_tensor = torch.tensor(attention_mask, dtype=torch.long)\n","        labels_tensor = torch.tensor(labels, dtype=torch.long)\n","\n","        return input_ids_tensor, attention_mask_tensor, labels_tensor\n"]},{"cell_type":"code","execution_count":null,"id":"b838775d","metadata":{"id":"b838775d"},"outputs":[],"source":["def create_dataloader(data, labels, tokenizer, batch_size=64, shuffle=True, max_len=512):\n","    dataset = SPKDataset(data, labels)\n","    collator = SPKCollator(tokenizer, max_len=max_len)\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collator, num_workers=0)\n","    return dataloader"]},{"cell_type":"code","execution_count":null,"id":"72656277","metadata":{"id":"72656277"},"outputs":[],"source":["train_loader = create_dataloader(X_train, y_train, wrapped_tokenizer, batch_size=16, shuffle=True, max_len=512)\n","val_loader = create_dataloader(X_val, y_val, wrapped_tokenizer, batch_size=16, shuffle=False, max_len=512)\n","test_loader = create_dataloader(X_test, y_test, wrapped_tokenizer, batch_size=16, shuffle=False, max_len=512)"]},{"cell_type":"code","execution_count":null,"id":"b7c887e2","metadata":{"id":"b7c887e2"},"outputs":[],"source":["class_weights_tensor = torch.tensor(list(class_weights.values())).to(device)\n","loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"]},{"cell_type":"code","execution_count":null,"id":"a060e1e3","metadata":{"id":"a060e1e3"},"outputs":[],"source":["def train(model, loader, optimizer, mode='train'):\n","  if mode == 'train':\n","    model.train()\n","  else:\n","    model.eval()\n","\n","  device = torch.device('cuda')\n","  amp = True\n","  scalar = torch.cuda.amp.GradScaler(enabled=amp)\n","  model.to(device)\n","\n","  all_predictions = []\n","  all_labels = []\n","\n","  for _, (input_ids, attention_mask, aligned_labels) in enumerate(loader):\n","    input_ids, attention_mask, aligned_labels = input_ids.to(device), attention_mask.to(device), aligned_labels.to(device)\n","\n","    # use fp16 to speed up\n","    with torch.cuda.amp.autocast(enabled=amp):\n","\n","      # feed the input to the model\n","      outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), labels=aligned_labels.to(device))\n","\n","      # compute the loss\n","      loss = outputs.loss\n","      # loss = loss_fn(outputs.logits, aligned_labels.to(torch.float32)) # with weighted loss\n","      # loss = loss_fn(outputs.logits, aligned_labels.to(torch.float32)) # with weighted loss\n","\n","      # store the predictions and labels\n","\n","      cur_predictions = outputs.logits.argmax(dim=-1).data.cpu().numpy().tolist()\n","      cur_labels = aligned_labels.data.cpu().numpy().tolist()\n","\n","      # Check if cur_predictions is a list of lists or a list of ints\n","      if all(isinstance(item, list) for item in cur_predictions):\n","        # flatten cur_predictions and cur_labels if they are lists of lists\n","        cur_predictions = [item for sublist in cur_predictions for item in sublist]\n","        cur_labels = [item for sublist in cur_labels for item in sublist]\n","\n","      all_predictions.extend(cur_predictions)\n","      all_labels.extend(cur_labels)\n","\n","    # print('{} step {} loss: {}'.format(mode, idx, loss.data.cpu().numpy()))\n","    if mode == 'train':\n","      # update the model parameters\n","      optimizer.zero_grad()\n","      if scalar is not None:\n","        scalar.scale(loss).backward()\n","        scalar.step(optimizer)\n","        scalar.update()\n","      else:\n","        loss.backward()\n","        optimizer.step()\n","  return all_predictions, all_labels\n","\n","#optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n","#predictions, labels = train(model, train_1k_loader, optim, mode='train')\n","#true_labels, true_predictions = postprocess(predictions, labels)\n","#print()"]},{"cell_type":"code","execution_count":null,"id":"a10d7285","metadata":{"id":"a10d7285"},"outputs":[],"source":["def obtain_performance(model, train_loader, val_loader, optim):\n","  best_val_micro_f1 = 0\n","  best_val_macro_f1 = 0\n","  best_val_macro_epoch = 0\n","  best_val_micro_epoch = 0\n","  for epoch in range(10):\n","    print('===================== Epoch {} ===================='.format(epoch))\n","    train_predictions, train_labels = train(model, train_loader, optim, mode='train')\n","    val_predictions, val_labels = train(model, val_loader, optim, mode='eval')\n","    # train_true_labels, train_true_predictions = postprocess(train_predictions, train_labels)\n","    # val_true_labels, val_true_predictions = postprocess(val_predictions, val_labels)\n","    train_true_labels = train_labels\n","    train_true_predictions = train_predictions\n","    val_true_labels = val_labels\n","    val_true_predictions = val_predictions\n","    # micro f1\n","    train_f1 = f1_score(train_true_labels, train_true_predictions, average='micro')\n","    val_f1 = f1_score(val_true_labels, val_true_predictions, average='micro')\n","    print('Micro Train F1: {}, Val F1: {}'.format(train_f1, val_f1))\n","    if val_f1 > best_val_micro_f1:\n","      best_val_micro_f1 = val_f1\n","      best_val_micro_epoch = epoch\n","    # macro f1\n","    train_f1 = f1_score(train_true_labels, train_true_predictions, average='macro')\n","    val_f1 = f1_score(val_true_labels, val_true_predictions, average='macro')\n","    # per class f1\n","    train_f1s = f1_score(train_true_labels, train_true_predictions, average=None)\n","    val_f1s = f1_score(val_true_labels, val_true_predictions, average=None)\n","    print('Per class Train F1s: {}, Val F1s: {}'.format(train_f1s, val_f1s))\n","    print('Macro Train F1: {}, Val F1: {}'.format(train_f1, val_f1))\n","    if val_f1 > best_val_macro_f1:\n","      best_val_macro_f1 = val_f1\n","      best_val_macro_epoch = epoch\n","  print('Best Val Micro F1: {}, Best Val Macro F1: {}'.format(best_val_micro_f1, best_val_macro_f1))\n","  print('Best Val Micro Epoch: {}, Best Val Macro Epoch: {}'.format(best_val_micro_epoch, best_val_macro_epoch))"]},{"cell_type":"code","execution_count":null,"id":"27b7537b","metadata":{"id":"27b7537b","outputId":"18c1df51-3f42-4dd2-d56f-f5a9ad96c9d7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(class_weights))"]},{"cell_type":"code","execution_count":null,"id":"50d9412a","metadata":{"id":"50d9412a"},"outputs":[],"source":["optim = torch.optim.Adam(model.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"fc7e6e5e","metadata":{"id":"fc7e6e5e","outputId":"09dec2bf-ee3c-46aa-cbd3-14fd018098de"},"outputs":[{"name":"stdout","output_type":"stream","text":["===================== Epoch 0 ====================\n","Micro Train F1: 0.28793903247183567, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.00970874 0.34262199 0.         0.10957255 0.00453515 0.37691596\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.12047919630429801, Val F1: 0.06334880522606154\n","===================== Epoch 1 ====================\n","Micro Train F1: 0.28180914512922467, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.32688844 0.         0.08872902 0.         0.37985352\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.11363870980030381, Val F1: 0.06579674416627704\n","===================== Epoch 2 ====================\n","Micro Train F1: 0.29042412193505635, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.34052701 0.         0.0771725  0.         0.38559197\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.11475592551682033, Val F1: 0.06334880522606154\n","===================== Epoch 3 ====================\n","Micro Train F1: 0.28520543406229293, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.33710542 0.         0.06042693 0.         0.37990581\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.11106259396606814, Val F1: 0.06334880522606154\n","===================== Epoch 4 ====================\n","Micro Train F1: 0.2820576540755467, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.32372026 0.         0.06100796 0.         0.38197008\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.10952832811010385, Val F1: 0.06579674416627704\n","===================== Epoch 5 ====================\n","Micro Train F1: 0.28644797879390327, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.32883203 0.         0.05616438 0.         0.38714703\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.11030620629588804, Val F1: 0.06579674416627704\n","===================== Epoch 6 ====================\n","Micro Train F1: 0.2890159045725646, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.33392456 0.         0.02177177 0.         0.38968699\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.10648333226933716, Val F1: 0.06579674416627704\n","===================== Epoch 7 ====================\n","Micro Train F1: 0.28479125248508946, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.31611545 0.         0.0282318  0.         0.39090825\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.10503649983114537, Val F1: 0.06334880522606154\n","===================== Epoch 8 ====================\n","Micro Train F1: 0.2885188866799205, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.34341576 0.         0.03963964 0.         0.38083055\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.10912656299851818, Val F1: 0.06579674416627704\n","===================== Epoch 9 ====================\n","Micro Train F1: 0.29348906560636184, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.31819926 0.         0.0031348  0.         0.40760146\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.1041336444013136, Val F1: 0.06334880522606154\n","Best Val Micro F1: 0.29918824893699264, Best Val Macro F1: 0.06579674416627704\n","Best Val Micro Epoch: 1, Best Val Macro Epoch: 1\n"]}],"source":["obtain_performance(model, train_loader, val_loader, optim)"]},{"cell_type":"code","execution_count":null,"id":"c13e9a5f","metadata":{"id":"c13e9a5f"},"outputs":[],"source":["torch.save(model.state_dict(), 'trained_model.pt')"]},{"cell_type":"code","execution_count":null,"id":"0e9d6d35","metadata":{"id":"0e9d6d35"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"b1947fee","metadata":{"id":"b1947fee"},"outputs":[],"source":["model.eval()\n"]},{"cell_type":"code","execution_count":null,"id":"ede43ea5","metadata":{"id":"ede43ea5","outputId":"904115ab-1773-4eac-df27-6b4203490139"},"outputs":[{"name":"stderr","output_type":"stream","text":["config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 483/483 [00:00<00:00, 3.52MB/s]\n","model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268M/268M [00:02<00:00, 104MB/s]  \n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","\n","    \"distilbert/distilbert-base-uncased\", num_labels=2,\n","\n",")"]},{"cell_type":"code","execution_count":null,"id":"399ced56","metadata":{"id":"399ced56","outputId":"0a3ae6fc-01db-4a11-adc0-7333f48cd227"},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not tuple","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m model([\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:1002\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1002\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[1;32m   1003\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1004\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1005\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1006\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1007\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1008\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1009\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1010\u001b[0m )\n\u001b[1;32m   1011\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:802\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m    803\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:4516\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[0;32m-> 4516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m input_ids[:, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m   4517\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4518\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4519\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4520\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4521\u001b[0m     )\n\u001b[1;32m   4523\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"]}],"source":["test = model([3]*5000)"]},{"cell_type":"code","execution_count":null,"id":"d0b6d074","metadata":{"id":"d0b6d074"},"outputs":[],"source":["inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"id":"cc3734d9","metadata":{"id":"cc3734d9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"be053705","metadata":{"id":"be053705","outputId":"3a9dd5f9-1574-47c1-dda5-8949b2539f97"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zubat/anaconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["from transformers import RwkvConfig, RwkvModel\n","import torch\n","inputs = {'input_ids':\n","          torch.tensor([[1]*6000]).to('cuda'),\n","          'attention_mask': torch.tensor([[1]*6000]).to('cuda')}\n","\n","\n","# Initializing a Rwkv configuration\n","\n","configuration = RwkvConfig(context_length=6000)\n","\n","# Initializing a model (with random weights) from the configuration\n","\n","model = RwkvModel(configuration)\n","\n","# Accessing the model configuration\n","\n","configuration = model.config\n","\n"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}