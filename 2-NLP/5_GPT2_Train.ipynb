{"cells":[{"cell_type":"markdown","id":"945d2086","metadata":{"id":"945d2086"},"source":["# 0 Set paths, devices, etc."]},{"cell_type":"code","source":["!pip install datasets\n","!pip install evaluate\n","!pip install transformers[torch]\n","!pip install accelerate -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZY8LoBlkKcR","executionInfo":{"status":"ok","timestamp":1710682587855,"user_tz":-60,"elapsed":72948,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"da3a99a3-6f77-4097-ad1f-623fe97754fe"},"id":"iZY8LoBlkKcR","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":2,"id":"16UUZ4LuPDU5","metadata":{"executionInfo":{"elapsed":29284,"status":"ok","timestamp":1710682617113,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"16UUZ4LuPDU5"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","# from collections import Counter\n","import torch\n","# from tqdm import tqdm\n","# from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import train_test_split\n","\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","from datasets import Dataset, DatasetDict\n","\n","# from huggingface_hub import notebook_login\n","\n","import torch.nn as nn\n","\n","from transformers import AutoModel, AutoModelForSequenceClassification, TrainingArguments, Trainer, PreTrainedTokenizerFast, AdamW, GPT2ForSequenceClassification\n","from transformers import default_data_collator #, LongformerForSequenceClassification, LongformerModel, LongformerConfig, DataCollatorWithPadding\n","from sklearn.metrics import f1_score, confusion_matrix #, accuracy_score, precision_score, recall_score\n","import evaluate\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["import accelerate\n","\n","accelerate.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"F_hOVmG8nwdf","executionInfo":{"status":"ok","timestamp":1710682617113,"user_tz":-60,"elapsed":9,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"c55b2e16-d7f9-4bfb-96e0-5681a4b7a3de"},"id":"F_hOVmG8nwdf","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.28.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"id":"4978325a","metadata":{"id":"4978325a"},"outputs":[],"source":["# notebook_login()"]},{"cell_type":"code","execution_count":4,"id":"mNy3kQcq3gHA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1586,"status":"ok","timestamp":1710682618693,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"mNy3kQcq3gHA","outputId":"e770f037-c4c5-4759-fd46-5c999b2a136a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"id":"dkmIqKEI4j1j","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710682618694,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"dkmIqKEI4j1j"},"outputs":[],"source":["data_dir = 'drive/MyDrive/neuro2voc/task_1/data/'\n","# data_dir = '/home/zubat/Fei/Task_1/outputs/'"]},{"cell_type":"code","execution_count":6,"id":"618f73da","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710682618694,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"},"user_tz":-60},"id":"618f73da","outputId":"e7851106-7a5e-454f-fcc0-d413b3579e5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()"]},{"cell_type":"markdown","id":"b78465e6","metadata":{"id":"b78465e6"},"source":["# 1 Load data and inspect"]},{"cell_type":"markdown","id":"59b5acfb","metadata":{"id":"59b5acfb"},"source":["### 1.0 select what you want to load"]},{"cell_type":"code","execution_count":7,"id":"13d1ef51","metadata":{"id":"13d1ef51","executionInfo":{"status":"ok","timestamp":1710682618694,"user_tz":-60,"elapsed":4,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["# file = 1\n","# file = 2\n","# file = 3\n","file = \"all\"\n","\n","\n","batch_size = 1\n","# batch_size = 30\n","# batch_size = 60\n","# batch_size = 120\n","# batch_size = 300\n","\n","# mode = \"temporal\"\n","mode = \"spatial\""]},{"cell_type":"markdown","id":"50204407","metadata":{"id":"50204407"},"source":["### 1.1 Load the data"]},{"cell_type":"code","execution_count":8,"id":"d3d28144","metadata":{"id":"d3d28144","executionInfo":{"status":"ok","timestamp":1710682636729,"user_tz":-60,"elapsed":18038,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["data_labels_dir = data_dir+\"3_data_labels_df_\"+mode+\"/\"\n","data_labels_df = pd.read_csv(f\"{data_labels_dir}data_labels_{file}_{batch_size}.csv\")\n","current_label_name = 'labels'"]},{"cell_type":"code","execution_count":9,"id":"c99cc4f1","metadata":{"id":"c99cc4f1","executionInfo":{"status":"ok","timestamp":1710682636730,"user_tz":-60,"elapsed":13,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["# If you need to rename column:\n","# data_labels_df.rename(columns={'labels': 'label'}, inplace=True)\n","# result_df_path_name = f\"{data_labels_dir}data_labels_{file}_{batch_size}_new.csv\"\n","# data_labels_df.to_csv(result_df_path_name, index=False)\n","# data_labels_df = pd.read_csv(f\"{data_labels_dir}data_labels_{file}_{batch_size}_new.csv\")\n","# current_label_name = 'label'"]},{"cell_type":"code","execution_count":10,"id":"ebc385b4","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ebc385b4","executionInfo":{"status":"ok","timestamp":1710682636730,"user_tz":-60,"elapsed":12,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"8b768517-65e6-4045-9f92-82ac5c18149d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                      data  labels\n","0        <|start|>0000000000000000000000000000000000000...       0\n","1        <|start|>0000000000000000000000000000000000000...       0\n","2        <|start|>0000000000000000000000000000000000000...       0\n","3        <|start|>0000000000000000000000000000000000000...       0\n","4        <|start|>0000000000000000000000000000000000000...       0\n","...                                                    ...     ...\n","7639648  <|start|>0000000000000000000000000000000000000...       3\n","7639649  <|start|>0000000000000000000000000000000000000...       3\n","7639650  <|start|>0000000000000000000000000000000000000...       3\n","7639651  <|start|>0000000000000000000000000000000000000...       3\n","7639652  <|start|>0000000000000000000000000000000000000...       3\n","\n","[7639653 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-cc10bc8d-c679-488e-a468-b631eb5889fa\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7639648</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7639649</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7639650</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7639651</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7639652</th>\n","      <td>&lt;|start|&gt;0000000000000000000000000000000000000...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7639653 rows Ã— 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc10bc8d-c679-488e-a468-b631eb5889fa')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cc10bc8d-c679-488e-a468-b631eb5889fa button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cc10bc8d-c679-488e-a468-b631eb5889fa');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bd3e6a33-1127-4cd6-8302-17facc9906d2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd3e6a33-1127-4cd6-8302-17facc9906d2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bd3e6a33-1127-4cd6-8302-17facc9906d2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data_labels_df"}},"metadata":{},"execution_count":10}],"source":["data_labels_df"]},{"cell_type":"code","execution_count":null,"id":"b5c51768","metadata":{"id":"b5c51768","outputId":"5a9f2b2c-302c-4237-c020-57682d0a28e1"},"outputs":[{"data":{"text/plain":["'<|start|>000000000000000000000000000000000000000000000000000000000000000000000000000<|end|>'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["data_labels_df['data'][0]"]},{"cell_type":"markdown","id":"f8f98939","metadata":{"id":"f8f98939"},"source":["#### 1.1.1 Downsample if needed"]},{"cell_type":"code","execution_count":null,"id":"5fef085d","metadata":{"id":"5fef085d"},"outputs":[],"source":["downsample_rate = 50000"]},{"cell_type":"code","execution_count":null,"id":"2f4604e2","metadata":{"id":"2f4604e2","outputId":"8a701539-982c-4d6d-fecc-b0447185eee4"},"outputs":[{"data":{"text/plain":["6"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["downsampled_df, _ = train_test_split(data_labels_df, test_size=1-downsample_rate/len(data_labels_df), stratify=data_labels_df[current_label_name], random_state=42)\n","data_labels_df = downsampled_df\n","max(data_labels_df[current_label_name])"]},{"cell_type":"markdown","id":"81187e68","metadata":{"id":"81187e68"},"source":["#### 1.1.2 With two-way classification if needed"]},{"cell_type":"code","execution_count":null,"id":"1e34cdd0","metadata":{"id":"1e34cdd0"},"outputs":[],"source":["# data_labels_df = data_labels_df[data_labels_df[current_label_name].isin([0, 1])]\n","# print(max(data_labels_df[current_label_name]))\n","# data_labels_df"]},{"cell_type":"markdown","id":"6630eb3c","metadata":{"id":"6630eb3c"},"source":["### 1.2 Converting df to dataset"]},{"cell_type":"code","execution_count":11,"id":"cda2316e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cda2316e","executionInfo":{"status":"ok","timestamp":1710682686001,"user_tz":-60,"elapsed":49278,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"b3346e04-3952-4382-f34c-799d813240e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['data', 'labels'],\n","    num_rows: 7639653\n","})"]},"metadata":{},"execution_count":11}],"source":["dataset = Dataset.from_pandas(data_labels_df)\n","# assert len(dataset[current_label_name])==len(dataset['data'])\n","assert len(dataset[current_label_name])==len(dataset['data'])\n","dataset"]},{"cell_type":"markdown","id":"882d90ce","metadata":{"id":"882d90ce"},"source":["### 1.3 Load tokenizer trained from the previous step"]},{"cell_type":"code","execution_count":12,"id":"5a805079","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a805079","executionInfo":{"status":"ok","timestamp":1710682686506,"user_tz":-60,"elapsed":508,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"2ff71ffc-7992-4c18-e326-52fca3210586"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded tokenizer:\n","Path: drive/MyDrive/neuro2voc/task_1/data/4_tokenizer/spatial_all_1\n","Mode: spatial\n","Batch: 1\n","File: all\n"]}],"source":["tokenizer_dir = f\"{data_dir}4_tokenizer/{mode}_all_{batch_size}\"\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_dir)\n","print(\"Loaded tokenizer:\")\n","print(f\"Path: {tokenizer_dir}\")\n","print(f\"Mode: {mode}\")\n","print(f\"Batch: {batch_size}\")\n","print(f\"File: {file}\")"]},{"cell_type":"markdown","id":"0d3df729","metadata":{"id":"0d3df729"},"source":["# 2 Prepare for the model"]},{"cell_type":"markdown","id":"c55f880c","metadata":{"id":"c55f880c"},"source":["### 2.1 Tokenize function"]},{"cell_type":"code","execution_count":13,"id":"0afe82ab","metadata":{"id":"0afe82ab","executionInfo":{"status":"ok","timestamp":1710682686508,"user_tz":-60,"elapsed":10,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["# no max length, no truncation\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"data\"])\n","\n","# def tokenize_function(examples):\n","#     return tokenizer(examples[\"text\"], max_length=512, truncation=True)"]},{"cell_type":"code","execution_count":null,"id":"fc87ba1d","metadata":{"id":"fc87ba1d","outputId":"027aa1e2-afe9-4388-ddf4-dd7fabe14395"},"outputs":[{"data":{"text/plain":["1000000000000000019884624838656"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.model_max_length"]},{"cell_type":"code","execution_count":14,"id":"1771140e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["285db89e7eb04f809422d3121bec4b6f","68ebc17b57cf4370a245470fa8ff238a","c2711d3f8ff94824a144e532be739561","7a11b721d5644f428da104c2a80d95da","597da3972c2f41e2920e2192ea3b0aad","da975516e26647b79f6febe2386fbbde","d5d11d35db1d45f78e7e70a8c5316313","dd486e271d334789a05097bfdc656a13","be660de680674843afc58bbbbc3a28df","ce214b3a4f0446ac9e92f60f7257cb10","22456ecbe78a42d5ba75146777d498ec"]},"id":"1771140e","executionInfo":{"status":"ok","timestamp":1710683010484,"user_tz":-60,"elapsed":323985,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"3450d632-7f73-4b2b-b185-dd62f01edf8b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/7639653 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"285db89e7eb04f809422d3121bec4b6f"}},"metadata":{}}],"source":["tokenized_dataset = dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":15,"id":"a1263779","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1263779","executionInfo":{"status":"ok","timestamp":1710683010486,"user_tz":-60,"elapsed":36,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"6e0c2a2e-1ade-49ee-daa9-852b37f3fcff"},"outputs":[{"output_type":"stream","name":"stdout","text":["<|start|>000000000000000000000000000000000000000000000000000000000000000000000000000<|end|>\n","{'input_ids': [0, 12, 1], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n","3\n"]}],"source":["# Play around with the data\n","\n","untokenized_sample = data_labels_df['data'][0]\n","tokenized_sample = tokenizer(untokenized_sample)\n","print(untokenized_sample)\n","print(tokenized_sample)\n","print(len(tokenized_sample['input_ids']))"]},{"cell_type":"code","execution_count":null,"id":"04e3fa23","metadata":{"id":"04e3fa23"},"outputs":[],"source":["# from tqdm import tqdm\n","\n","# for n in tqdm(range(7639653)):\n","#     if len(tokenized_dataset[n]['input_ids']) > 3:\n","#         print(n)"]},{"cell_type":"markdown","id":"3467fa8d","metadata":{"id":"3467fa8d"},"source":["### 2.2 Train Test Split"]},{"cell_type":"code","execution_count":16,"id":"7a5d893b","metadata":{"id":"7a5d893b","executionInfo":{"status":"ok","timestamp":1710683014237,"user_tz":-60,"elapsed":3765,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["# 0.7 train\n","train_rest_split = tokenized_dataset.train_test_split(test_size=0.3)\n","# 0.15 val + 0.15 test\n","val_test_split = train_rest_split['test'].train_test_split(test_size=0.5)\n","\n","dataset_dict = DatasetDict({\n","    'train': train_rest_split['train'],\n","    'validation': val_test_split['train'],\n","    'test': val_test_split['test']\n","})"]},{"cell_type":"markdown","id":"439d3025","metadata":{"id":"439d3025"},"source":["### 2.3 Data collator"]},{"cell_type":"code","execution_count":17,"id":"8523923a","metadata":{"id":"8523923a","executionInfo":{"status":"ok","timestamp":1710683014237,"user_tz":-60,"elapsed":5,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["data_collator = default_data_collator"]},{"cell_type":"code","execution_count":18,"id":"5c6eb73d","metadata":{"id":"5c6eb73d","executionInfo":{"status":"ok","timestamp":1710683014238,"user_tz":-60,"elapsed":5,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["# data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"]},{"cell_type":"markdown","id":"9fedceb9","metadata":{"id":"9fedceb9"},"source":["### 2.4 Model"]},{"cell_type":"markdown","id":"c98803d3","metadata":{"id":"c98803d3"},"source":["#### 2.4.1 Number of labels"]},{"cell_type":"code","execution_count":19,"id":"e9353b2e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9353b2e","executionInfo":{"status":"ok","timestamp":1710683041447,"user_tz":-60,"elapsed":27213,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"d0da9dab-44ba-49fc-a5f6-6aa87e1fca1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of labels = 7\n"]}],"source":["print(\"number of labels =\", max(tokenized_dataset[current_label_name])-min(tokenized_dataset[current_label_name])+1)\n","if file != \"all\":\n","    assert max(tokenized_dataset[current_label_name]) < 6\n","else:\n","    assert max(tokenized_dataset[current_label_name]) < 8\n","assert min(tokenized_dataset[current_label_name]) >= 0\n","if max(tokenized_dataset[current_label_name]) == 1:\n","    print(\"Check if you are doing a binary classification.\")"]},{"cell_type":"code","execution_count":20,"id":"8cd983e1","metadata":{"id":"8cd983e1","executionInfo":{"status":"ok","timestamp":1710683041451,"user_tz":-60,"elapsed":21,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["num_labels = 7\n","# num_labels = 6\n","# num_labels = 2\n","if num_labels == 7:\n","    assert file == \"all\""]},{"cell_type":"markdown","id":"1254a468","metadata":{"id":"1254a468"},"source":["### 2.4.2 Load the model"]},{"cell_type":"code","execution_count":26,"id":"e0cc4969","metadata":{"id":"e0cc4969","executionInfo":{"status":"ok","timestamp":1710682068527,"user_tz":-60,"elapsed":3385,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["from transformers import GPT2Config, GPT2Model\n","\n","configuration = GPT2Config(vocab_size = 7107, bos_token_id = 0, eos_token_id = 1)\n","model = GPT2Model(configuration)\n","configuration = model.config"]},{"cell_type":"code","execution_count":null,"id":"e1db57a6","metadata":{"id":"e1db57a6","outputId":"3ab166e4-1d68-4e56-bdf6-458e038c4227"},"outputs":[{"name":"stdout","output_type":"stream","text":["PreTrainedTokenizerFast(name_or_path='/home/zubat/Fei/Task_1/outputs/4_tokenizer/spatial_all_1', vocab_size=7107, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'pad_token': '[PAD]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"<|start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<|end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t7107: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n"]}],"source":["print(tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"01123504","metadata":{"id":"01123504","outputId":"7e99a521-0298-45ff-bbf8-5e56cfc6c7a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.37.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 7107\n","}\n","\n"]}],"source":["print(configuration)"]},{"cell_type":"code","execution_count":null,"id":"1f37468a","metadata":{"id":"1f37468a","outputId":"3215597c-2c7a-4c8c-b519-122f04cb9ea3"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT2Model(\n","  (wte): Embedding(7107, 768)\n","  (wpe): Embedding(1024, 768)\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (h): ModuleList(\n","    (0-11): 12 x GPT2Block(\n","      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (attn): GPT2Attention(\n","        (c_attn): Conv1D()\n","        (c_proj): Conv1D()\n","        (attn_dropout): Dropout(p=0.1, inplace=False)\n","        (resid_dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (mlp): GPT2MLP(\n","        (c_fc): Conv1D()\n","        (c_proj): Conv1D()\n","        (act): NewGELUActivation()\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"id":"7b94a902","metadata":{"id":"7b94a902","outputId":"65be6a0a-4028-4e26-fc74-9674e9c5e4c9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# checkpoint = 'bert-base-uncased'\n","# model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=6) # 7 for data3 & combined data"]},{"cell_type":"code","execution_count":21,"id":"baf8313c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baf8313c","executionInfo":{"status":"ok","timestamp":1710683060552,"user_tz":-60,"elapsed":19116,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"da499141-2958-4cf6-d4c7-312c6fb49d0e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at microsoft/DialogRPT-updown and are newly initialized because the shapes did not match:\n","- score.weight: found shape torch.Size([1, 1024]) in the checkpoint and torch.Size([7, 1024]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["GPT2ForSequenceClassification(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 1024)\n","    (wpe): Embedding(1024, 1024)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-23): 24 x GPT2Block(\n","        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (score): Linear(in_features=1024, out_features=7, bias=False)\n",")"]},"metadata":{},"execution_count":21}],"source":["model = GPT2ForSequenceClassification.from_pretrained(\"microsoft/DialogRPT-updown\", num_labels=num_labels, ignore_mismatched_sizes=True)\n","model"]},{"cell_type":"code","execution_count":null,"id":"6fa6d7c4","metadata":{"id":"6fa6d7c4"},"outputs":[],"source":["# model = AutoModel.from_pretrained(\"allenai/longformer-base-4096\", num_labels=6)"]},{"cell_type":"code","execution_count":null,"id":"cebc3ae7","metadata":{"id":"cebc3ae7","outputId":"ddac0441-b4a3-4d5b-83e9-93fc8b650916"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\", num_labels=6)"]},{"cell_type":"markdown","id":"866b05ab","metadata":{"id":"866b05ab"},"source":["### 2.5 Training arguments"]},{"cell_type":"markdown","id":"56bb1f78","metadata":{"id":"56bb1f78"},"source":["#### 2.5.1 Metrics"]},{"cell_type":"code","execution_count":22,"id":"4f1a86e5","metadata":{"id":"4f1a86e5","executionInfo":{"status":"ok","timestamp":1710683061445,"user_tz":-60,"elapsed":896,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["metric = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":23,"id":"5c7a53b9","metadata":{"id":"5c7a53b9","executionInfo":{"status":"ok","timestamp":1710683061446,"user_tz":-60,"elapsed":8,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"markdown","id":"ec84273d","metadata":{"id":"ec84273d"},"source":["#### 2.5.2 Training Arguments"]},{"cell_type":"code","execution_count":24,"id":"47e603e2","metadata":{"id":"47e603e2","executionInfo":{"status":"ok","timestamp":1710683061447,"user_tz":-60,"elapsed":7,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}}},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir = \"./results\",\n","    num_train_epochs = 10,\n","    per_device_train_batch_size = 1,\n","    per_device_eval_batch_size = 1,\n","    evaluation_strategy = \"epoch\",\n","    gradient_accumulation_steps = 64,\n","    learning_rate = 1.25e-5,\n","    warmup_steps = 500,\n","    weight_decay = 0.01,\n","    logging_dir = \"./logs\"\n",")\n","\n","# training_args = TrainingArguments(\n","#     output_dir = \"./results\",\n","#     num_train_epochs = 10,\n","#     per_device_train_batch_size = 16,\n","#     per_device_eval_batch_size = 16,\n","#     gradient_accumulation_steps = 4,\n","#     evaluation_strategy = \"epoch\",\n","#     learning_rate = 5e-5,\n","#     warmup_steps = 500,\n","#     weight_decay = 0.01,\n","#     logging_dir = \"./logs\",\n","# )"]},{"cell_type":"code","execution_count":null,"id":"9a097d47","metadata":{"id":"9a097d47"},"outputs":[],"source":["# optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n","# optimizer = AdamW(model.parameters(), lr=1e-5)"]},{"cell_type":"markdown","id":"687230fc","metadata":{"id":"687230fc"},"source":["### 2.6 Wrap everything above into trainer"]},{"cell_type":"code","execution_count":25,"id":"3636446a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3636446a","executionInfo":{"status":"ok","timestamp":1710683061447,"user_tz":-60,"elapsed":6,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"e83160d4-76e4-412d-df27-18095a19641b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset = dataset_dict['train'],\n","    eval_dataset = dataset_dict['validation'],\n","    compute_metrics = compute_metrics,\n","    tokenizer = tokenizer,\n","    data_collator = data_collator\n",")"]},{"cell_type":"code","execution_count":null,"id":"3054f5b9","metadata":{"id":"3054f5b9","outputId":"c318c0b0-aaf2-4830-d18b-88af646a9219"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['data', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 5347757\n","})"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["dataset_dict['train']"]},{"cell_type":"markdown","id":"c0dc5698","metadata":{"id":"c0dc5698"},"source":["# 3 TRAIN"]},{"cell_type":"code","execution_count":27,"id":"bd33b515","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"bd33b515","executionInfo":{"status":"error","timestamp":1710684247665,"user_tz":-60,"elapsed":257479,"user":{"displayName":"Askr Gao","userId":"17726271072640278750"}},"outputId":"dc8aba9d-f2a4-49f8-ca8e-97831a805147"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='835580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [     3/835580 01:42 < 23744:24:13, 0.01 it/s, Epoch 0.00/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2911\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"markdown","id":"e2dd0499","metadata":{"id":"e2dd0499"},"source":["# 4 Test"]},{"cell_type":"code","execution_count":null,"id":"b61c5ffe","metadata":{"id":"b61c5ffe","outputId":"221db886-1127-415a-81c0-0729e60227c7"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                       \n"," 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3000/5240 [6:17:30<1:54:27,  3.07s/it]"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.3781766891479492, 'eval_accuracy': 0.4679506290620714, 'eval_runtime': 270.9478, 'eval_samples_per_second': 61.898, 'eval_steps_per_second': 61.898, 'epoch': 11.45}\n","{'eval_loss': 1.3781766891479492, 'eval_accuracy': 0.4679506290620714, 'eval_runtime': 270.9478, 'eval_samples_per_second': 61.898, 'eval_steps_per_second': 61.898, 'epoch': 11.45}\n"]}],"source":["test_result = trainer.evaluate(dataset_dict['train'])\n","print(test_result)"]},{"cell_type":"code","execution_count":null,"id":"e41c06a5","metadata":{"id":"e41c06a5","outputId":"ea410c77-f265-4bf9-938a-1f04118f1326"},"outputs":[{"name":"stderr","output_type":"stream","text":[]},{"name":"stderr","output_type":"stream","text":[]}],"source":["predictions = trainer.predict(dataset_dict['test'])\n","logits = predictions.predictions\n","predicted_classes = np.argmax(logits, axis=1)\n","true_labels = dataset_dict['test']['labels']"]},{"cell_type":"markdown","id":"033b3ff8","metadata":{"id":"033b3ff8"},"source":["# 5 Result"]},{"cell_type":"code","execution_count":null,"id":"a1f6ba3e","metadata":{"id":"a1f6ba3e","outputId":"cc9d3493-f78b-49d1-e86d-d3743a8c3908"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x800 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["cm = confusion_matrix(true_labels, predicted_classes)\n","\n","# Plotting the confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"markdown","id":"ae6e79a2","metadata":{"id":"ae6e79a2"},"source":["temporal 120: doesnt work, predict only label 1 and 5\n","\n","spatial data: doesnt work, predict only label"]},{"cell_type":"markdown","id":"f712223a","metadata":{"id":"f712223a"},"source":["for binary classification\n","\n","\n"," 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1802/2340 [37:25<10:22,  1.16s/it]\n","{'eval_loss': 0.8176514506340027, 'eval_accuracy': 0.78, 'eval_runtime': 65.3502, 'eval_samples_per_second': 10.712, 'eval_steps_per_second': 3.581, 'epoch': 7.7}"]},{"cell_type":"code","execution_count":null,"id":"5eb6122b","metadata":{"id":"5eb6122b"},"outputs":[],"source":["name_model = \"temporal_from_300ms_gpt2_5h/\"\n","trainer.save_model(f\"{data_dir}5_models/{name_model}\")"]},{"cell_type":"markdown","id":"755a8b66","metadata":{"id":"755a8b66"},"source":["# Archived Codes"]},{"cell_type":"code","execution_count":null,"id":"DYwN8ffrQ3d3","metadata":{"id":"DYwN8ffrQ3d3"},"outputs":[],"source":["class SPKDataset(Dataset):\n","    def __init__(self, dataset, label, split='train'):\n","        self.dataset = dataset\n","        self.split = split\n","        self.label = label\n","        self.label2id = {label: label - 2 for label in range(2, 9)}\n","\n","    def __getitem__(self, item):\n","        data = self.dataset[item]\n","        label = self.label[item]\n","        mapped_label = self.label2id.get(label, label)\n","        return data, mapped_label\n","\n","    def __len__(self):\n","        return len(self.dataset)"]},{"cell_type":"code","execution_count":null,"id":"eeef2556","metadata":{"id":"eeef2556"},"outputs":[],"source":["class SPKNoPadCollator:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, batch):\n","        data, labels = zip(*batch)\n","\n","        # tokenizer without padding and truncation\n","        inputs = self.tokenizer(list(data), return_tensors='pt')\n","\n","        # extract input_ids and attention_mask\n","        input_ids = inputs['input_ids']\n","        attention_mask = inputs['attention_mask']\n","        labels_tensor = torch.tensor(labels, dtype=torch.long)\n","\n","        return input_ids, attention_mask, labels_tensor"]},{"cell_type":"code","execution_count":null,"id":"7CBPI_u0USN3","metadata":{"id":"7CBPI_u0USN3"},"outputs":[],"source":["class SPKPadCollator:\n","    def __init__(self, tokenizer, max_len=512):\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __call__(self, batch):\n","        data, labels = zip(*batch)\n","\n","        # tokenize WITH padding\n","        input_ids = []\n","        attention_mask = []\n","        for datapoint in data:\n","            encoded = self.tokenizer.encode(datapoint)\n","            ids = encoded.ids\n","\n","            # truncate\n","            ids = ids[:self.max_len]\n","\n","            # create attention mask and pad input_ids\n","            mask = [1] * len(ids)\n","            num_pad = self.max_len - len(ids)\n","            ids += [self.tokenizer.token_to_id(\"[PAD]\")] * num_pad\n","            mask += [0] * num_pad\n","\n","            input_ids.append(ids)\n","            attention_mask.append(mask)\n","\n","        # convert to tensors\n","        input_ids_tensor = torch.tensor(input_ids, dtype=torch.long)\n","        attention_mask_tensor = torch.tensor(attention_mask, dtype=torch.long)\n","        labels_tensor = torch.tensor(labels, dtype=torch.long)\n","\n","        return input_ids_tensor, attention_mask_tensor, labels_tensor\n"]},{"cell_type":"code","execution_count":null,"id":"b838775d","metadata":{"id":"b838775d"},"outputs":[],"source":["def create_dataloader(data, labels, tokenizer, batch_size=64, shuffle=True, max_len=512):\n","    dataset = SPKDataset(data, labels)\n","    collator = SPKCollator(tokenizer, max_len=max_len)\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collator, num_workers=0)\n","    return dataloader"]},{"cell_type":"code","execution_count":null,"id":"72656277","metadata":{"id":"72656277"},"outputs":[],"source":["train_loader = create_dataloader(X_train, y_train, wrapped_tokenizer, batch_size=16, shuffle=True, max_len=512)\n","val_loader = create_dataloader(X_val, y_val, wrapped_tokenizer, batch_size=16, shuffle=False, max_len=512)\n","test_loader = create_dataloader(X_test, y_test, wrapped_tokenizer, batch_size=16, shuffle=False, max_len=512)"]},{"cell_type":"code","execution_count":null,"id":"b7c887e2","metadata":{"id":"b7c887e2"},"outputs":[],"source":["class_weights_tensor = torch.tensor(list(class_weights.values())).to(device)\n","loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"]},{"cell_type":"code","execution_count":null,"id":"a060e1e3","metadata":{"id":"a060e1e3"},"outputs":[],"source":["def train(model, loader, optimizer, mode='train'):\n","  if mode == 'train':\n","    model.train()\n","  else:\n","    model.eval()\n","\n","  device = torch.device('cuda')\n","  amp = True\n","  scalar = torch.cuda.amp.GradScaler(enabled=amp)\n","  model.to(device)\n","\n","  all_predictions = []\n","  all_labels = []\n","\n","  for _, (input_ids, attention_mask, aligned_labels) in enumerate(loader):\n","    input_ids, attention_mask, aligned_labels = input_ids.to(device), attention_mask.to(device), aligned_labels.to(device)\n","\n","    # use fp16 to speed up\n","    with torch.cuda.amp.autocast(enabled=amp):\n","\n","      # feed the input to the model\n","      outputs = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device), labels=aligned_labels.to(device))\n","\n","      # compute the loss\n","      loss = outputs.loss\n","      # loss = loss_fn(outputs.logits, aligned_labels.to(torch.float32)) # with weighted loss\n","      # loss = loss_fn(outputs.logits, aligned_labels.to(torch.float32)) # with weighted loss\n","\n","      # store the predictions and labels\n","\n","      cur_predictions = outputs.logits.argmax(dim=-1).data.cpu().numpy().tolist()\n","      cur_labels = aligned_labels.data.cpu().numpy().tolist()\n","\n","      # Check if cur_predictions is a list of lists or a list of ints\n","      if all(isinstance(item, list) for item in cur_predictions):\n","        # flatten cur_predictions and cur_labels if they are lists of lists\n","        cur_predictions = [item for sublist in cur_predictions for item in sublist]\n","        cur_labels = [item for sublist in cur_labels for item in sublist]\n","\n","      all_predictions.extend(cur_predictions)\n","      all_labels.extend(cur_labels)\n","\n","    # print('{} step {} loss: {}'.format(mode, idx, loss.data.cpu().numpy()))\n","    if mode == 'train':\n","      # update the model parameters\n","      optimizer.zero_grad()\n","      if scalar is not None:\n","        scalar.scale(loss).backward()\n","        scalar.step(optimizer)\n","        scalar.update()\n","      else:\n","        loss.backward()\n","        optimizer.step()\n","  return all_predictions, all_labels\n","\n","#optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n","#predictions, labels = train(model, train_1k_loader, optim, mode='train')\n","#true_labels, true_predictions = postprocess(predictions, labels)\n","#print()"]},{"cell_type":"code","execution_count":null,"id":"a10d7285","metadata":{"id":"a10d7285"},"outputs":[],"source":["def obtain_performance(model, train_loader, val_loader, optim):\n","  best_val_micro_f1 = 0\n","  best_val_macro_f1 = 0\n","  best_val_macro_epoch = 0\n","  best_val_micro_epoch = 0\n","  for epoch in range(10):\n","    print('===================== Epoch {} ===================='.format(epoch))\n","    train_predictions, train_labels = train(model, train_loader, optim, mode='train')\n","    val_predictions, val_labels = train(model, val_loader, optim, mode='eval')\n","    # train_true_labels, train_true_predictions = postprocess(train_predictions, train_labels)\n","    # val_true_labels, val_true_predictions = postprocess(val_predictions, val_labels)\n","    train_true_labels = train_labels\n","    train_true_predictions = train_predictions\n","    val_true_labels = val_labels\n","    val_true_predictions = val_predictions\n","    # micro f1\n","    train_f1 = f1_score(train_true_labels, train_true_predictions, average='micro')\n","    val_f1 = f1_score(val_true_labels, val_true_predictions, average='micro')\n","    print('Micro Train F1: {}, Val F1: {}'.format(train_f1, val_f1))\n","    if val_f1 > best_val_micro_f1:\n","      best_val_micro_f1 = val_f1\n","      best_val_micro_epoch = epoch\n","    # macro f1\n","    train_f1 = f1_score(train_true_labels, train_true_predictions, average='macro')\n","    val_f1 = f1_score(val_true_labels, val_true_predictions, average='macro')\n","    # per class f1\n","    train_f1s = f1_score(train_true_labels, train_true_predictions, average=None)\n","    val_f1s = f1_score(val_true_labels, val_true_predictions, average=None)\n","    print('Per class Train F1s: {}, Val F1s: {}'.format(train_f1s, val_f1s))\n","    print('Macro Train F1: {}, Val F1: {}'.format(train_f1, val_f1))\n","    if val_f1 > best_val_macro_f1:\n","      best_val_macro_f1 = val_f1\n","      best_val_macro_epoch = epoch\n","  print('Best Val Micro F1: {}, Best Val Macro F1: {}'.format(best_val_micro_f1, best_val_macro_f1))\n","  print('Best Val Micro Epoch: {}, Best Val Macro Epoch: {}'.format(best_val_micro_epoch, best_val_macro_epoch))"]},{"cell_type":"code","execution_count":null,"id":"27b7537b","metadata":{"id":"27b7537b","outputId":"18c1df51-3f42-4dd2-d56f-f5a9ad96c9d7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(class_weights))"]},{"cell_type":"code","execution_count":null,"id":"50d9412a","metadata":{"id":"50d9412a"},"outputs":[],"source":["optim = torch.optim.Adam(model.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"fc7e6e5e","metadata":{"id":"fc7e6e5e","outputId":"09dec2bf-ee3c-46aa-cbd3-14fd018098de"},"outputs":[{"name":"stdout","output_type":"stream","text":["===================== Epoch 0 ====================\n","Micro Train F1: 0.28793903247183567, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.00970874 0.34262199 0.         0.10957255 0.00453515 0.37691596\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.12047919630429801, Val F1: 0.06334880522606154\n","===================== Epoch 1 ====================\n","Micro Train F1: 0.28180914512922467, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.32688844 0.         0.08872902 0.         0.37985352\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.11363870980030381, Val F1: 0.06579674416627704\n","===================== Epoch 2 ====================\n","Micro Train F1: 0.29042412193505635, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.34052701 0.         0.0771725  0.         0.38559197\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.11475592551682033, Val F1: 0.06334880522606154\n","===================== Epoch 3 ====================\n","Micro Train F1: 0.28520543406229293, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.33710542 0.         0.06042693 0.         0.37990581\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.11106259396606814, Val F1: 0.06334880522606154\n","===================== Epoch 4 ====================\n","Micro Train F1: 0.2820576540755467, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.32372026 0.         0.06100796 0.         0.38197008\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.10952832811010385, Val F1: 0.06579674416627704\n","===================== Epoch 5 ====================\n","Micro Train F1: 0.28644797879390327, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.32883203 0.         0.05616438 0.         0.38714703\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.11030620629588804, Val F1: 0.06579674416627704\n","===================== Epoch 6 ====================\n","Micro Train F1: 0.2890159045725646, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.33392456 0.         0.02177177 0.         0.38968699\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.10648333226933716, Val F1: 0.06579674416627704\n","===================== Epoch 7 ====================\n","Micro Train F1: 0.28479125248508946, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.31611545 0.         0.0282318  0.         0.39090825\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.10503649983114537, Val F1: 0.06334880522606154\n","===================== Epoch 8 ====================\n","Micro Train F1: 0.2885188866799205, Val F1: 0.29918824893699264\n","Per class Train F1s: [0.         0.34341576 0.         0.03963964 0.         0.38083055\n"," 0.        ], Val F1s: [0.         0.         0.         0.         0.         0.46057721\n"," 0.        ]\n","Macro Train F1: 0.10912656299851818, Val F1: 0.06579674416627704\n","===================== Epoch 9 ====================\n","Micro Train F1: 0.29348906560636184, Val F1: 0.28488596830305374\n","Per class Train F1s: [0.         0.31819926 0.         0.0031348  0.         0.40760146\n"," 0.        ], Val F1s: [0.         0.44344164 0.         0.         0.         0.\n"," 0.        ]\n","Macro Train F1: 0.1041336444013136, Val F1: 0.06334880522606154\n","Best Val Micro F1: 0.29918824893699264, Best Val Macro F1: 0.06579674416627704\n","Best Val Micro Epoch: 1, Best Val Macro Epoch: 1\n"]}],"source":["obtain_performance(model, train_loader, val_loader, optim)"]},{"cell_type":"code","execution_count":null,"id":"c13e9a5f","metadata":{"id":"c13e9a5f"},"outputs":[],"source":["torch.save(model.state_dict(), 'trained_model.pt')"]},{"cell_type":"code","execution_count":null,"id":"0e9d6d35","metadata":{"id":"0e9d6d35"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"b1947fee","metadata":{"id":"b1947fee"},"outputs":[],"source":["model.eval()\n"]},{"cell_type":"code","execution_count":null,"id":"ede43ea5","metadata":{"id":"ede43ea5","outputId":"904115ab-1773-4eac-df27-6b4203490139"},"outputs":[{"name":"stderr","output_type":"stream","text":["config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [00:00<00:00, 3.52MB/s]\n","model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 268M/268M [00:02<00:00, 104MB/s]  \n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","\n","    \"distilbert/distilbert-base-uncased\", num_labels=2,\n","\n",")"]},{"cell_type":"code","execution_count":null,"id":"399ced56","metadata":{"id":"399ced56","outputId":"0a3ae6fc-01db-4a11-adc0-7333f48cd227"},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not tuple","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m model([\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:1002\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1002\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[1;32m   1003\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1004\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1005\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1006\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1007\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1008\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1009\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1010\u001b[0m )\n\u001b[1;32m   1011\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:802\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m    803\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:4516\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[0;32m-> 4516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m input_ids[:, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m   4517\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4518\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4519\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4520\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4521\u001b[0m     )\n\u001b[1;32m   4523\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"]}],"source":["test = model([3]*5000)"]},{"cell_type":"code","execution_count":null,"id":"d0b6d074","metadata":{"id":"d0b6d074"},"outputs":[],"source":["inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"id":"cc3734d9","metadata":{"id":"cc3734d9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"be053705","metadata":{"id":"be053705","outputId":"3a9dd5f9-1574-47c1-dda5-8949b2539f97"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zubat/anaconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["from transformers import RwkvConfig, RwkvModel\n","import torch\n","inputs = {'input_ids':\n","          torch.tensor([[1]*6000]).to('cuda'),\n","          'attention_mask': torch.tensor([[1]*6000]).to('cuda')}\n","\n","\n","# Initializing a Rwkv configuration\n","\n","configuration = RwkvConfig(context_length=6000)\n","\n","# Initializing a model (with random weights) from the configuration\n","\n","model = RwkvModel(configuration)\n","\n","# Accessing the model configuration\n","\n","configuration = model.config\n","\n"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"285db89e7eb04f809422d3121bec4b6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68ebc17b57cf4370a245470fa8ff238a","IPY_MODEL_c2711d3f8ff94824a144e532be739561","IPY_MODEL_7a11b721d5644f428da104c2a80d95da"],"layout":"IPY_MODEL_597da3972c2f41e2920e2192ea3b0aad"}},"68ebc17b57cf4370a245470fa8ff238a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da975516e26647b79f6febe2386fbbde","placeholder":"â€‹","style":"IPY_MODEL_d5d11d35db1d45f78e7e70a8c5316313","value":"Map:â€‡100%"}},"c2711d3f8ff94824a144e532be739561":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd486e271d334789a05097bfdc656a13","max":7639653,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be660de680674843afc58bbbbc3a28df","value":7639653}},"7a11b721d5644f428da104c2a80d95da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce214b3a4f0446ac9e92f60f7257cb10","placeholder":"â€‹","style":"IPY_MODEL_22456ecbe78a42d5ba75146777d498ec","value":"â€‡7639653/7639653â€‡[05:24&lt;00:00,â€‡35388.72â€‡examples/s]"}},"597da3972c2f41e2920e2192ea3b0aad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da975516e26647b79f6febe2386fbbde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d11d35db1d45f78e7e70a8c5316313":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd486e271d334789a05097bfdc656a13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be660de680674843afc58bbbbc3a28df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce214b3a4f0446ac9e92f60f7257cb10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22456ecbe78a42d5ba75146777d498ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}