{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_binary(input_data, output_data, sample_idx, save_path=None):\n",
    "    \"\"\"Plot heatmap comparison between input and output data\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Plot input data\n",
    "    im1 = ax1.imshow(input_data, aspect='auto', interpolation='nearest', cmap='gray_r', vmin=0, vmax=1)\n",
    "    ax1.set_title('Original Data')\n",
    "    ax1.set_xlabel('Time (ms)')\n",
    "    # Set x-axis ticks to show time in ms\n",
    "    xticks = ax1.get_xticks()\n",
    "    ax1.set_xticks(xticks)\n",
    "    ax1.set_xticklabels([f'{int(x/30)}' for x in xticks])\n",
    "    ax1.set_xlim(0, input_data.shape[1])  # Show full range\n",
    "    ax1.text(input_data.shape[1], -1, '30ms', ha='right')\n",
    "    ax1.set_ylabel('Neuron')\n",
    "    plt.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # Plot output data\n",
    "    im2 = ax2.imshow(output_data, aspect='auto', interpolation='nearest', cmap='gray_r', vmin=0)\n",
    "    ax2.set_title('Reconstructed Data')\n",
    "    ax2.set_xlabel('Time (ms)')\n",
    "    # Set x-axis ticks to show time in ms\n",
    "    xticks = ax2.get_xticks()\n",
    "    ax2.set_xticks(xticks)\n",
    "    ax2.set_xticklabels([f'{int(x/30)}' for x in xticks])\n",
    "    ax2.set_xlim(0, output_data.shape[1])  # Show full range\n",
    "\n",
    "    ax2.set_ylabel('Neuron')\n",
    "    plt.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([75, 900])\n",
      "Output shape: torch.Size([75, 900])\n",
      "Input shape: torch.Size([75, 900])\n",
      "Output shape: torch.Size([75, 900])\n",
      "Input shape: torch.Size([75, 900])\n",
      "Output shape: torch.Size([75, 900])\n",
      "Input shape: torch.Size([75, 900])\n",
      "Output shape: torch.Size([75, 900])\n",
      "Input shape: torch.Size([75, 900])\n",
      "Output shape: torch.Size([75, 900])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    # Load input tensor\n",
    "    input_path = os.path.join(\"model_outputs_binary\", f\"input_{i}.pt\")\n",
    "    output_path = os.path.join(\"model_outputs_binary\", f\"output_{i}.pt\")\n",
    "    \n",
    "    try:\n",
    "        input_tensor = torch.load(input_path, weights_only=True).squeeze(0).to(torch.float32)\n",
    "        output_tensor = torch.load(output_path, weights_only=True).squeeze(0).to(torch.float32)\n",
    "        \n",
    "        print(f\"Input shape: {input_tensor.shape}\")\n",
    "        print(f\"Output shape: {output_tensor.shape}\")\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        input_data = input_tensor.numpy()\n",
    "        output_data = output_tensor.numpy()\n",
    "        \n",
    "        # Create visualization\n",
    "        plot_comparison_binary(\n",
    "            input_data,\n",
    "            output_data,\n",
    "            sample_idx=i,\n",
    "            save_path=os.path.join(\"visualization_results\", f\"comparison_binary_encodec_{i}.pdf\")\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample {i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_binned(input_data, output_data, sample_idx, save_path=None):\n",
    "    \"\"\"Plot heatmap comparison between input and output data\"\"\"\n",
    "    plt.figure(figsize=(12, 5), dpi=300)\n",
    "    \n",
    "    # Get max value for normalization\n",
    "    vmax = max(input_data.max(), output_data.max())\n",
    "    vmin = 0\n",
    "    \n",
    "    # Calculate extent\n",
    "    factor = 10\n",
    "    extent = [0, input_data.shape[1]*factor, input_data.shape[0], 0]  # [left, right, bottom, top]\n",
    "    \n",
    "    # Plot input data\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(input_data, \n",
    "              aspect='auto',\n",
    "              cmap='viridis',\n",
    "              extent=extent,\n",
    "              vmin=vmin,\n",
    "              vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.title('Original Data')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Neuron')\n",
    "    \n",
    "    # Plot output data\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(output_data,\n",
    "              aspect='auto',\n",
    "              cmap='viridis', \n",
    "              extent=extent,\n",
    "              vmin=vmin,\n",
    "              vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.title('Reconstructed Data')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Neuron')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([75, 27])\n",
      "Output shape: torch.Size([75, 27])\n",
      "Input shape: torch.Size([75, 27])\n",
      "Output shape: torch.Size([75, 27])\n",
      "Input shape: torch.Size([75, 27])\n",
      "Output shape: torch.Size([75, 27])\n",
      "Input shape: torch.Size([75, 27])\n",
      "Output shape: torch.Size([75, 27])\n",
      "Input shape: torch.Size([75, 27])\n",
      "Output shape: torch.Size([75, 27])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    # Load input tensor\n",
    "    input_path = os.path.join(\"model_outputs_binned_maintain_time\", f\"input_{i}.pt\")\n",
    "    output_path = os.path.join(\"model_outputs_binned_maintain_time\", f\"output_{i}.pt\")\n",
    "    \n",
    "    try:\n",
    "        input_tensor = torch.load(input_path, weights_only=True).squeeze(0).to(torch.float32)\n",
    "        output_tensor = torch.load(output_path, weights_only=True).squeeze(0).to(torch.float32)\n",
    "        \n",
    "        print(f\"Input shape: {input_tensor.shape}\")\n",
    "        print(f\"Output shape: {output_tensor.shape}\")\n",
    "        \n",
    "        # Convert tensors to numpy arrays\n",
    "        input_data = input_tensor.numpy()\n",
    "        output_data = output_tensor.numpy()\n",
    "        \n",
    "        # Create visualization\n",
    "        plot_comparison_binned(\n",
    "            input_data,\n",
    "            output_data,\n",
    "            sample_idx=i,\n",
    "            save_path=os.path.join(\"visualization_results\", f\"comparison_binned_encodec_{i}.pdf\")\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample {i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro2voc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
